{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jznUqok0oJ3_",
        "outputId": "056b007e-0978-4dc1-949b-1f5b96c0971e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.impute import SimpleImputer\n",
        "import logging\n",
        "import abc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "from scipy.stats import multivariate_normal\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from tqdm import trange\n",
        "import tqdm\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "import sklearn\n",
        "import itertools\n",
        "import operator\n",
        "from lightgbm import LGBMClassifier\n",
        "import warnings\n",
        "from collections import Counter\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "G8FazMfuoPm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import trange\n",
        "import tqdm\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import logging\n",
        "\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, train_link, test_link, y_var, drop_cols, scaler=None, imputer=None):\n",
        "        '''\n",
        "        :param train_link: link to the training data\n",
        "        :param test_link: link to the test data\n",
        "        :param y_var: name of the target variable\n",
        "        :param drop_cols: list of columns to drop\n",
        "        :param scaler: scaler to use for scaling the data\n",
        "        :param imputer: imputer to use for imputing missing values\n",
        "        '''\n",
        "        df_normal = pd.read_csv(train_link)\n",
        "        df_test = pd.read_csv(test_link)\n",
        "        self.X_train, self.y_train = self.drop_y(df_normal, y_var)\n",
        "        self.X_test, self.y_test = self.drop_y(df_test, y_var)\n",
        "        self.X_train = self.drop_cols(self.X_train, drop_cols)\n",
        "        self.X_test = self.drop_cols(self.X_test, drop_cols)\n",
        "        self.col_names = self.get_colnames(self.X_train)\n",
        "        self.X_train = self.check_and_impute_missing(self.X_train, imputer)\n",
        "        self.X_test = self.check_and_impute_missing(self.X_test, imputer)\n",
        "        self.X_train, self.X_test, self.scaler_function = self.scale_data(self.X_train, self.X_test, self.col_names,\n",
        "                                                                          scaler)\n",
        "\n",
        "    def drop_y(self, df, y_var):\n",
        "        '''\n",
        "        :param df: dataframe to drop the target variable from\n",
        "        :param y_var: name of the target variable\n",
        "        :return: dataframe with the target variable dropped\n",
        "        '''\n",
        "        y = df[y_var]\n",
        "        x_data = df.drop(columns=[y_var], axis=1)\n",
        "        return x_data, y\n",
        "\n",
        "    def drop_cols(self, df, cols):\n",
        "        '''\n",
        "        :param df: dataframe to drop the columns from\n",
        "        :param cols: list of columns to drop\n",
        "        :return: dataframe with the columns dropped\n",
        "        '''\n",
        "        data = df.drop(columns=cols, axis=1)\n",
        "        return data\n",
        "\n",
        "    def get_colnames(self, df):\n",
        "        '''\n",
        "        :param df: dataframe to get the column names from \n",
        "        :return: list of column names\n",
        "        '''\n",
        "        return list(df.columns)\n",
        "\n",
        "    def check_and_impute_missing(self, df, imputer):\n",
        "        '''\n",
        "        :param df: dataframe to check for missing values\n",
        "        :param imputer: imputer to use for imputing missing values\n",
        "        :return: dataframe with missing values imputed\n",
        "        '''\n",
        "        # Check for missing values\n",
        "        if imputer is None:\n",
        "            imputer = SimpleImputer(strategy='mean')\n",
        "        missing = df.isnull().sum()\n",
        "        if missing.sum() == 0:\n",
        "            # No missing values, return the original dataframe\n",
        "            return df\n",
        "        else:\n",
        "            # Impute missing values with the mean of the column\n",
        "            imputed_df = imputer.fit_transform(df)\n",
        "            imputed_df = pd.DataFrame(imputed_df, columns=self.col_names)\n",
        "            return imputed_df\n",
        "\n",
        "    def scale_data(self, train_df, test_df, colnames, scaler):\n",
        "        '''\n",
        "        :param train_df: training dataframe to scale\n",
        "        :param test_df: test dataframe to scale\n",
        "        :param colnames: list of column names\n",
        "        :param scaler: scaler to use for scaling the data\n",
        "        :return: scaled training and test dataframes\n",
        "        '''\n",
        "         # if no scaler is passed, use the standard scaler\n",
        "        if scaler is None: \n",
        "            scaler = preprocessing.StandardScaler()\n",
        "        x_scaled_train = scaler.fit_transform(train_df)\n",
        "        # fit and transform the training data\n",
        "        df_train = pd.DataFrame(x_scaled_train, columns=self.col_names)\n",
        "        # transform the test data\n",
        "        x_scaled_test = scaler.transform(test_df)\n",
        "        df_test = pd.DataFrame(x_scaled_test, columns=self.col_names)\n",
        "        return df_train, df_test, scaler\n",
        "\n"
      ],
      "metadata": {
        "id": "7lVCWobMoRxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_link = \"/content/drive/My Drive/TEPdata/experiment_1/normal_10000.csv\"\n",
        "\n",
        "test_link = \"/content/drive/My Drive/TEPdata/experiment_1/df_IDV(5).csv\""
      ],
      "metadata": {
        "id": "q37UNZmZoTTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = DataProcessor(train_link, test_link, \"Fault\", \"Unnamed: 0\")\n",
        "X_train = processor.X_train\n",
        "y_train = processor.y_train\n",
        "X_test = processor.X_test\n",
        "y_test = processor.y_test\n",
        "scaler = processor.scaler_function"
      ],
      "metadata": {
        "id": "R1d06r1poUsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMED():\n",
        "    def __init__(self, num_epochs: int = 5, batch_size: int = 20, lr: float = 1e-3,\n",
        "                 hidden_size: int = 5, sequence_length: int = 30, train_gaussian_percentage: float = 0.25,\n",
        "                 n_layers: int = 1, use_bias: bool = True, dropout: float = 0.2):\n",
        "        \n",
        "\n",
        "\n",
        "        # set the random seed\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.prediction_details = {}\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.hidden_size = hidden_size\n",
        "        self.sequence_length = sequence_length\n",
        "        self.train_gaussian_percentage = train_gaussian_percentage\n",
        "        self.n_layers = n_layers\n",
        "        self.use_bias = use_bias\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # will be used to store the trained LSTM model\n",
        "        self.lstmed = None\n",
        "        # will be used to store the mean and covariance of the Gaussian distribution\n",
        "        self.mean, self.cov = None, None\n",
        "\n",
        "    def to_device(self, model):\n",
        "        '''\n",
        "        Move the model to the device specified by the user\n",
        "        :param model: model to move to the device\n",
        "        '''\n",
        "        model.to(self.device)\n",
        "\n",
        "    def fit(self, X: pd.DataFrame):\n",
        "      \n",
        "        data = X.values\n",
        "        # create sequences of data by taking self.sequence_length consecutive rows\n",
        "        sequences = [data[i:i + self.sequence_length] for i in range(data.shape[0] - self.sequence_length + 1)]\n",
        "        # shuffle the sequences\n",
        "        indices = np.random.permutation(len(sequences))\n",
        "        # split the sequences into a training set and a \"train Gaussian\" set\n",
        "        split_point = int(self.train_gaussian_percentage * len(sequences))\n",
        "        # training set\n",
        "        train_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, drop_last=True,\n",
        "                                  sampler=SubsetRandomSampler(indices[:-split_point]), pin_memory=True)\n",
        "        train_gaussian_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, drop_last=True,\n",
        "                                           sampler=SubsetRandomSampler(indices[-split_point:]), pin_memory=True)\n",
        "\n",
        "        # create the LSTM model using the LSTMEDModule class\n",
        "        self.lstmed = LSTMEDModule(X.shape[1], self.hidden_size,\n",
        "                                   self.n_layers, self.use_bias, self.dropout)\n",
        "        # move the model to the device specified by the user\n",
        "        self.to_device(self.lstmed)\n",
        "        # create an Adam optimizer\n",
        "        optimizer = torch.optim.Adam(self.lstmed.parameters(), lr=self.lr)\n",
        "        # set the model to training mode\n",
        "        # In PyTorch, the training mode of a model refers to whether the model's parameters are being updated\n",
        "        # during the forward pass or not. When a model is in training mode, its parameters are being updated\n",
        "        # based on the gradients computed during the backward pass. When a model is in evaluation mode,\n",
        "        # its parameters are not updated and certain layers (e.g. dropout layers) may behave differently.\n",
        "        self.lstmed.train()\n",
        "        # trange is a wrapper around the range function to provide a smart progress meter\n",
        "        # when looping over an iterable. It can also be used as a context manager\n",
        "        for epoch in trange(self.num_epochs):\n",
        "            # log the epoch number\n",
        "            logging.debug(f'Epoch {epoch + 1}/{self.num_epochs}.')\n",
        "            # iterate over the training set\n",
        "            for ts_batch in train_loader:\n",
        "                # move the batch to the device specified by the user\n",
        "                output = self.lstmed(self.to_var(ts_batch))\n",
        "                # compute the loss between the model's predictions and the actual values using the MSE loss function\n",
        "                loss = nn.MSELoss(size_average=False)(output, self.to_var(ts_batch.float()))\n",
        "                # clear the gradients\n",
        "                self.lstmed.zero_grad()\n",
        "                # compute the gradients\n",
        "                loss.backward()\n",
        "                # update the model's parameters\n",
        "                optimizer.step()\n",
        "        # set the model to evaluation mode\n",
        "        # In PyTorch, the evaluation mode of a model refers to a setting in which the model's parameters\n",
        "        # are not being updated during the forward pass. In other words, when a model is in evaluation mode,\n",
        "        # the gradients are not computed during the backward pass and the model's parameters are not updated.\n",
        "        self.lstmed.eval()\n",
        "        error_vectors = []\n",
        "        # iterate over the \"train Gaussian\" set\n",
        "        for ts_batch in train_gaussian_loader:\n",
        "            # forward pass\n",
        "            output = self.lstmed(self.to_var(ts_batch))\n",
        "            # compute the error between the model's predictions and the actual values\n",
        "            error = nn.L1Loss(reduce=False)(output, self.to_var(ts_batch.float()))\n",
        "            # store the error vectors\n",
        "            error_vectors += list(error.view(-1, X.shape[1]).data.cpu().numpy())\n",
        "        # compute the mean and covariance of the error vectors\n",
        "        self.mean = np.mean(error_vectors, axis=0)\n",
        "        self.cov = np.cov(error_vectors, rowvar=False)\n",
        "    \n",
        "    def to_var(self, t, **kwargs):\n",
        "   \n",
        "        # send the tensor to the device\n",
        "        t = t.to(self.device)\n",
        "        # convert the tensor to a variable\n",
        "        return Variable(t, **kwargs)\n",
        "\n",
        "    def predict(self, X: pd.DataFrame):\n",
        "    \n",
        "        data = X.values\n",
        "        sequences = [data[i:i + self.sequence_length] for i in range(data.shape[0] - self.sequence_length + 1)]\n",
        "        data_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, shuffle=False, drop_last=False)\n",
        "        # set the model to evaluation mode\n",
        "        self.lstmed.eval()\n",
        "        # create a multivariate normal distribution\n",
        "        mvnormal = multivariate_normal(self.mean, self.cov, allow_singular=True)\n",
        "        scores = []\n",
        "        outputs = []\n",
        "        errors = []\n",
        "        # iterate over the data loader\n",
        "        for idx, ts in enumerate(data_loader):\n",
        "            # forward pass\n",
        "            output = self.lstmed(self.to_var(ts))\n",
        "            # compute the error between the model's predictions and the actual values using the L1 loss function\n",
        "            # The error is calculated using the L1 loss function because it is a commonly used measure of\n",
        "            # absolute error between two tensors. The L1 loss function is defined as the sum of the absolute\n",
        "            # differences between the elements of the two tensors. It is often used because it is more robust\n",
        "            # to outliers than the mean squared error (MSE) loss, which is another commonly used loss function.\n",
        "            error = nn.L1Loss(reduce=False)(output, self.to_var(ts.float()))\n",
        "            # compute the negative log probability of the error under the multivariate normal distribution\n",
        "            # The scores are calculated using the negative log probability of the error under a multivariate\n",
        "            # normal distribution because the model is assumed to have a Gaussian distribution of errors.\n",
        "            # The negative log probability is used as a measure of the likelihood of the error under the\n",
        "            # assumed distribution. This likelihood can then be used to determine whether a particular sample\n",
        "            # is an outlier or not, as samples with low likelihood are less likely to have been generated by\n",
        "            # the model and are more likely to be anomalies.\n",
        "            score = -mvnormal.logpdf(error.view(-1, X.shape[1]).data.cpu().numpy())\n",
        "            scores.append(score.reshape(ts.size(0), self.sequence_length))\n",
        "            outputs.append(output.cpu().data.numpy())\n",
        "            errors.append(error.cpu().data.numpy())\n",
        "\n",
        "        # concatenate the scores\n",
        "        scores = np.concatenate(scores)\n",
        "        # create a matrix of NaNs with the same shape as the data\n",
        "        scores_matrix = np.full((self.sequence_length, data.shape[0]), np.nan)\n",
        "        # iterate over the scores\n",
        "        for i, score in enumerate(scores):\n",
        "            # fill the matrix with the scores\n",
        "            scores_matrix[i % self.sequence_length, i:i + self.sequence_length] = score\n",
        "        # average the scores over each self.sequence_length consecutive entries\n",
        "        scores = np.nanmean(scores_matrix, axis=0)\n",
        "\n",
        "    \n",
        "        # concatenate the outputs\n",
        "        outputs = np.concatenate(outputs)\n",
        "        # create a matrix of NaNs with the same shape as the data\n",
        "        scores_matrix = np.full((self.sequence_length, X.shape[0], X.shape[1]), np.nan)\n",
        "        # iterate over the outputs\n",
        "        for i, output in enumerate(outputs):\n",
        "            # fill the matrix with the outputs\n",
        "            scores_matrix[i % self.sequence_length, i:i + self.sequence_length, :] = output\n",
        "        # average the outputs over each self.sequence_length consecutive entries\n",
        "        self.prediction_details.update({'reconstructions_mean': np.nanmean(scores_matrix, axis=0).T})\n",
        "        # concatenate the errors\n",
        "        errors = np.concatenate(errors)\n",
        "        # create a matrix of NaNs with the same shape as the data\n",
        "        scores_matrix = np.full((self.sequence_length, X.shape[0], X.shape[1]), np.nan)\n",
        "        # iterate over the errors\n",
        "        for i, error in enumerate(errors):\n",
        "            # fill the matrix with the errors\n",
        "            scores_matrix[i % self.sequence_length, i:i + self.sequence_length, :] = error\n",
        "        # average the errors over each self.sequence_length consecutive entries\n",
        "        self.prediction_details.update({'errors_mean': np.nanmean(scores_matrix, axis=0).T})\n",
        "        # return the scores and the prediction details\n",
        "        return scores, self.prediction_details\n",
        "\n",
        "\n",
        "class LSTMEDModule(nn.Module):\n",
        "    def __init__(self, n_features: int, hidden_size: int,\n",
        "                 n_layers: int, use_bias: bool, dropout: float):\n",
        "    \n",
        "        super().__init__()\n",
        "        # set the device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.n_features = n_features\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        self.use_bias = use_bias\n",
        "        self.dropout = dropout\n",
        "        # encoder\n",
        "        self.encoder = nn.LSTM(self.n_features, self.hidden_size, batch_first=True,\n",
        "                               num_layers=self.n_layers, bias=self.use_bias, dropout=self.dropout)\n",
        "        # send the encoder to the device\n",
        "        self.to_device(self.encoder)\n",
        "        # decoder\n",
        "        self.decoder = nn.LSTM(self.n_features, self.hidden_size, batch_first=True,\n",
        "                               num_layers=self.n_layers, bias=self.use_bias, dropout=self.dropout)\n",
        "        # send the decoder to the device\n",
        "        self.to_device(self.decoder)\n",
        "        # linear layer\n",
        "        self.hidden2output = nn.Linear(self.hidden_size, self.n_features)\n",
        "        # send the linear layer to the device\n",
        "        self.to_device(self.hidden2output)\n",
        "\n",
        "    def to_device(self, model):\n",
        "        '''\n",
        "        Move the model to the device specified by the user\n",
        "        :param model: model to move to the device\n",
        "        '''\n",
        "        model.to(self.device)\n",
        "\n",
        " \n",
        "\n",
        "    def to_var(self, t, **kwargs):\n",
        "     \n",
        "        # send the tensor to the device\n",
        "        t = t.to(self.device)\n",
        "        # convert the tensor to a variable\n",
        "        return Variable(t, **kwargs)\n",
        "\n",
        "    def _init_hidden(self, batch_size):\n",
        "       \n",
        "        return (self.to_var(torch.Tensor(self.n_layers, batch_size, self.hidden_size).zero_()),\n",
        "                self.to_var(torch.Tensor(self.n_layers, batch_size, self.hidden_size).zero_()))\n",
        "\n",
        "    def forward(self, ts_batch):\n",
        "\n",
        "        # get the batch size\n",
        "        batch_size = ts_batch.shape[0]\n",
        "        # initialize the hidden state of the encoder\n",
        "        enc_hidden = self._init_hidden(batch_size)\n",
        "        # apply the encoder to the input time series data\n",
        "        _, enc_hidden = self.encoder(ts_batch.float(), enc_hidden)\n",
        "        # initialize the hidden state of the decoder\n",
        "        dec_hidden = enc_hidden\n",
        "        # initialize the output tensor\n",
        "        output = self.to_var(torch.Tensor(ts_batch.size()).zero_())\n",
        "        # This means that the model starts at the final time step of the input data and works its way\n",
        "        # backwards to the initial time step.\n",
        "\n",
        "        # iterate over the time steps of the input time series data\n",
        "        for i in reversed(range(ts_batch.shape[1])):\n",
        "            # apply the linear layer to the current hidden state of the decoder\n",
        "            output[:, i, :] = self.hidden2output(dec_hidden[0][0, :])\n",
        "            if self.training:\n",
        "                # apply the decoder to the input time series data at the current time step\n",
        "                _, dec_hidden = self.decoder(ts_batch[:, i].unsqueeze(1).float(), dec_hidden)\n",
        "            else:\n",
        "                # apply the decoder to the output produced by the model at the current time step\n",
        "                _, dec_hidden = self.decoder(output[:, i].unsqueeze(1), dec_hidden)\n",
        "\n",
        "        # return the output of the model\n",
        "        return output"
      ],
      "metadata": {
        "id": "wrN6M56AoXDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMED()\n",
        "model.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZGVAvwtoZCp",
        "outputId": "00324958-2723-44a2-bf4f-c14b418eb09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:53<00:00, 10.79s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Point"
      ],
      "metadata": {
        "id": "mGb62tLKIw5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ruptures"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ67y3CptuIf",
        "outputId": "cf573b9d-b956-4e2e-a17a-27136f3939e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ruptures\n",
            "  Downloading ruptures-1.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ruptures) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from ruptures) (1.7.3)\n",
            "Installing collected packages: ruptures\n",
            "Successfully installed ruptures-1.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ruptures as rpt"
      ],
      "metadata": {
        "id": "gAXxlBWyt7xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ChangePoint(X_test,penalty,model = \"PELT\"):\n",
        "    if model ==\"PELT\":\n",
        "        algo = rpt.KernelCPD(kernel=\"rbf\", min_size=2).fit(X_test.values)\n",
        "    elif model ==\"BottomUp\":\n",
        "        algo = rpt.detection.bottomup.BottomUp(model = \"rbf\").fit(X_test.values)\n",
        "    else:\n",
        "        return \"Error: Please enter PELT or BottomUp\"\n",
        "\n",
        "    test_length = len(X_test)\n",
        "    bkps = algo.predict(pen=penalty)\n",
        "\n",
        "    if len(bkps) % 2 != 0:\n",
        "        bkps.pop()\n",
        "    output = [0] * test_length\n",
        "    for i in range(0,len(bkps),2):\n",
        "        for j in range(bkps[i],bkps[i+1]+1):\n",
        "            if j < test_length:\n",
        "                output[j] = 1\n",
        "            else:\n",
        "                return output\n",
        "    return output\n",
        "    \n",
        "\n",
        "y_pred = ChangePoint(X_test,20)"
      ],
      "metadata": {
        "id": "mA90rd0aC3Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(fpr, tpr):\n",
        "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
        "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
        "    #plt.plot(fpr,tpr,label=\"AUC=\"+str(round(auc,4)))\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "#y_true = y_test[10:len(aa)]\n",
        "#y_scores = aa[10:len(aa)]\n",
        "y_true = y_test\n",
        "y_scores =yy\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "print(roc_auc_score(y_true, y_scores))\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "plot_roc_curve(fpr, tpr)\n",
        "\n",
        "# fix this code\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "beEIWxGD53ZH",
        "outputId": "2a303081-8ed5-4d04-94d6-54fb5b1e62fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8296300752461723\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyod "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6VLM5z8PWMw",
        "outputId": "8e2e0a6e-4d67-43bc-8500-3ba0c8627a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyod\n",
            "  Downloading pyod-1.0.7.tar.gz (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.7/147.7 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pyod) (1.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from pyod) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.8/dist-packages (from pyod) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from pyod) (1.7.3)\n",
            "Requirement already satisfied: scikit_learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from pyod) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pyod) (0.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.51->pyod) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.51->pyod) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.51->pyod) (57.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn>=0.20.0->pyod) (3.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pyod) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pyod) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pyod) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pyod) (0.5.3)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pyod) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21->statsmodels->pyod) (2022.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.51->pyod) (3.11.0)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.0.7-py3-none-any.whl size=181101 sha256=a5f63d0182c1cc2a8a7e46eb0d5f4dc2e75aca1165bc7abbca047f21b0d759ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/e2/c1/1c7fd8b261e72411f6509afb429c84532e40ddcd96074473f4\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-1.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install combo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1ECxhKZPu0D",
        "outputId": "7641e3f0-1553-4607-96bb-5797f9235647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting combo\n",
            "  Downloading combo-0.1.3.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from combo) (1.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from combo) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.8/dist-packages (from combo) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.8/dist-packages (from combo) (0.56.4)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.8/dist-packages (from combo) (1.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from combo) (1.7.3)\n",
            "Requirement already satisfied: scikit_learn>=0.20 in /usr/local/lib/python3.8/dist-packages (from combo) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.35->combo) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.35->combo) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.35->combo) (6.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn>=0.20->combo) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->combo) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->combo) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->combo) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->combo) (3.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pyod->combo) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pyod->combo) (0.12.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.35->combo) (3.11.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pyod->combo) (0.5.3)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pyod->combo) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21->statsmodels->pyod->combo) (2022.7)\n",
            "Building wheels for collected packages: combo\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.3-py3-none-any.whl size=42885 sha256=315576c2c481f3b6f98df2f11f3f4ee04cd027a02198be576277e9b587b10dc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/44/39/0667fea44a2dfe692cc2a51f0f79ea49b9dee7def53594ef2e\n",
            "Successfully built combo\n",
            "Installing collected packages: combo\n",
            "Successfully installed combo-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _precision(tp,fp):\n",
        "    pre = tp / float(tp + fp)\n",
        "    return pre \n",
        "\n",
        "def _recall(tp,fn):\n",
        "    rec= tp / float(tp + fn)\n",
        "    return rec \n",
        "\n",
        "def _f1(pre,rec):\n",
        "    '''\n",
        "    F1 = 2 * (precision * recall) / (precision + recall)\n",
        "    '''\n",
        "    f1 = 2 * (pre * rec) / (pre + rec)\n",
        "    return f1\n",
        "\n",
        "def print_results(accuracy, pre, rec, f1,roc):\n",
        "    print(\"Accuracy: {}%\".format(round(accuracy*100,2)))\n",
        "    print(\"Precision: {}%\".format(round(pre*100,2)))\n",
        "    print(\"Recall: {}%\".format(round(rec*100,2)))\n",
        "    print(\"F1 Score: {}%\".format(round(f1*100,2)))\n",
        "    print(\"ROCAUC: {}%\".format(round(roc*100,2)))\n",
        "    \n",
        "def calculate_results_print(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    TP = cm[0,0]\n",
        "    TN = cm[1,1]\n",
        "    FP = cm[0,1]\n",
        "    FN = cm[1,0]\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = _precision(TP,FP)\n",
        "    recall = _recall(TP,FN)\n",
        "    f1 = _f1(precision,recall)\n",
        "    roc = roc_auc_score(y_test, y_pred)\n",
        "    print_results(accuracy, precision, recall, f1,roc)"
      ],
      "metadata": {
        "id": "l1_JgsBCUyk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyod.models.ecod import ECOD\n",
        "from pyod.models.abod import ABOD\n",
        "from pyod.models.lunar import LUNAR\n",
        "from pyod.models.vae import VAE\n",
        "from pyod.models.alad import ALAD\n",
        "from pyod.models.so_gaal import SO_GAAL\n",
        "from pyod.models.knn import KNN\n",
        "#KNN(method='mean',contamination=outliers_fraction)"
      ],
      "metadata": {
        "id": "Z2OOaWM9VxD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install hyperopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK8OD7xmef4X",
        "outputId": "e9ee0bc7-ce4f-4ebd-980e-3611ea9e825c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.8/dist-packages (from hyperopt) (4.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from hyperopt) (4.64.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from hyperopt) (3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from hyperopt) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from hyperopt) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from pymongo->hyperopt) (2.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Spaces -> define the parameter area across which to optimize\n",
        "knn_space = {\"contamination\": hp.uniform(\"contamination\",0.1, 0.25),\n",
        "             \"method\" : hp.choice(\"method\",['largest', 'mean', 'median']),\n",
        "             \"algorithm\" : hp.choice(\"algorithm\", ['auto', 'ball_tree', 'kd_tree'])}\n",
        "\n",
        "vae_space = {\"gamma\": hp.uniform(\"gamma\", 0.5, 3),\n",
        "            \"batch_size\" : hp.choice(\"batch_size\", [32,64,128,256,512]),\n",
        "            \"epochs\" : hp.choice(\"epochs\", [10,25,50,100,250]),\n",
        "            \"dropout_rate\" : hp.uniform(\"dropout_rate\", 0.1, 0.7),\n",
        "            \"contamination\": hp.uniform(\"contamination\",0.1, 0.25),\n",
        "            \"l2_regularizer\" :hp.uniform(\"l2_regularizer\", 0.1, 0.7)}\n",
        "\n",
        "so_gaal_space = {\"contamination\": hp.uniform(\"contamination\",0.1, 0.25),\n",
        "                 \"lr_d\": hp.uniform(\"lr_d\", 0.0001,0.01),\n",
        "                 \"lr_g\": hp.uniform(\"lr_g\", 0.00001,0.001),\n",
        "                 \"momentum\": hp.uniform(\"momentum\", 0.1,0.9) }\n",
        "\n",
        "alad_space = {\"batch_size\" : hp.uniform(\"batch_size\", 32, 256),\n",
        "              \"contamination\": hp.uniform(\"contamination\",0.1, 0.25),\n",
        "              \"dropout_rate\" : hp.uniform(\"dropout_rate\", 0.1, 0.7)}\n",
        "\n",
        "ecod_space = {\"contamination\": hp.uniform(\"contamination\",0.1, 0.25)}\n",
        "\n",
        "abod_space = {\"contamination\": hp.uniform(\"contamination\",0.1, 0.25),\n",
        "              \"n_neighbors\":hp.uniform(\"n_neighbors\",10, 50)}\n",
        "\n",
        "lunar_space = {\"model_type\": hp.choice(\"model_type\",['WEIGHT', 'SCORE']),\n",
        "               \"n_neighbors\":hp.uniform(\"n_neighbors\",5, 25),\n",
        "               \"negative_sampling\" : hp.choice(\"negative_sampling\",['UNIFORM', 'SUBSPACE', 'MIXED']),\n",
        "               \"val_size\": hp.uniform(\"val_size\",0.1, 0.25),\n",
        "               \"epsilon\": hp.uniform(\"epsilon\",0.05, 0.2),\n",
        "               \"lr\": hp.uniform(\"lr\",0.0001, 0.01),\n",
        "               \"wd\": hp.uniform(\"wd\",0.05, 0.2) }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t3cIEdxhvrjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(space):\n",
        "    # Instantiate the classifier\n",
        "    clf = VAE(epochs = space[\"epochs\"],gamma = space[\"gamma\"],\n",
        "              batch_size = space[\"batch_size\"],\n",
        "              dropout_rate = space[\"dropout_rate\"],\n",
        "              contamination = space[\"contamination\"],\n",
        "              l2_regularizer = space[\"l2_regularizer\"] )\n",
        "    \n",
        "  \n",
        "    \n",
        "    # Fit the classsifier\n",
        "    clf.fit(X_train)\n",
        "    \n",
        "    # Predict on Cross Validation data\n",
        "    pred = clf.predict(X_test)\n",
        "    \n",
        "    # Calculate our Metric - accuracy\n",
        "    #accuracy = accuracy_score(pred, pred>0.5)\n",
        "    accuracy = f1_score(y_test,pred)\n",
        "# return needs to be in this below format. We use negative of accuracy since we want to maximize it.\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }"
      ],
      "metadata": {
        "id": "qxbAiiQX5G0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import Trials\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=vae_space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=10,\n",
        "            trials=trials)\n",
        "print(best)"
      ],
      "metadata": {
        "id": "Zc-p1L5B5wyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im[p]\n",
        "with open('Names.csv', 'w') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(cars)"
      ],
      "metadata": {
        "id": "4zmBV0kHmPvq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}