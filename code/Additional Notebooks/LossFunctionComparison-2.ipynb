{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndQAcUheyPDy",
        "outputId": "e8d3e455-38f0-462e-95c4-3ac7e7bed407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-_CGucVAyQbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from preprocess import *\n",
        "from detector import *"
      ],
      "metadata": {
        "id": "D6axDLC2yR8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_link = \"/content/drive/My Drive/TEPdata/normal_10000.csv\"\n",
        "test_link = \"/content/drive/My Drive/TEPdata/df_test_idv4_10000.csv\"\n",
        "model_link = \"/content/b256_e10000_h25.pth\"\n",
        "processor = DataProcessor(train_link, test_link, \"Fault\", \"Unnamed: 0\")\n",
        "X_train = processor.X_train\n",
        "y_train = processor.y_train\n",
        "X_test = processor.X_test\n",
        "y_test = processor.y_test\n",
        "scaler = processor.scaler_function\n",
        "col_names = processor.col_names\n"
      ],
      "metadata": {
        "id": "ryXGtIgRyLoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas-profiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma3YiDvjcpuy",
        "outputId": "760fe402-e653-4fb4-d179-c9955792c08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas-profiling in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.8/dist-packages (from pandas-profiling) (1.3.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from pandas-profiling) (1.15.0)\n",
            "Requirement already satisfied: matplotlib>=1.4 in /usr/local/lib/python3.8/dist-packages (from pandas-profiling) (3.5.3)\n",
            "Requirement already satisfied: jinja2>=2.8 in /usr/local/lib/python3.8/dist-packages (from pandas-profiling) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.8->pandas-profiling) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4->pandas-profiling) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4->pandas-profiling) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4->pandas-profiling) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4->pandas-profiling) (1.22.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4->pandas-profiling) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4->pandas-profiling) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4->pandas-profiling) (7.1.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4->pandas-profiling) (4.38.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19->pandas-profiling) (2022.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "MXIp3h12dPOn",
        "outputId": "9dae5370-1b8f-4c46-f8aa-b9560cd01889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      XMEAS(1)  XMEAS(2)  XMEAS(3)  XMEAS(4)  XMEAS(5)  XMEAS(6)  XMEAS(7)  \\\n",
              "0    -0.048347  0.123632 -0.159818  1.180660  2.005828  0.539664  0.214687   \n",
              "1    -0.041608  0.783922  0.038085  0.923513 -0.340695  2.065275 -0.007759   \n",
              "2     0.008368  0.090755  0.502525  0.057563  0.528490  0.121041 -0.096771   \n",
              "3    -0.026874  0.120640 -1.176303  1.435335 -1.174407  1.486478 -0.044917   \n",
              "4    -0.284680 -0.390610  0.205190  1.077877 -0.043286 -0.173478  0.028830   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9995  1.994365 -0.242611 -0.512596  0.758539 -0.528398 -0.228012 -1.615394   \n",
              "9996  0.110475  2.236481 -0.337915 -1.134547 -1.372783 -0.288344 -1.600317   \n",
              "9997  0.256299 -0.693700  0.542803 -0.634375 -0.124653  2.101598 -1.810683   \n",
              "9998  0.045981  0.011734 -0.586771 -1.741825 -0.515844 -1.184408 -1.855771   \n",
              "9999  0.045674 -1.186775 -0.627300 -0.362506  0.993095 -0.685113 -2.353346   \n",
              "\n",
              "      XMEAS(8)  XMEAS(9)  XMEAS(10)  ...    XMV(2)    XMV(3)    XMV(4)  \\\n",
              "0    -0.653729 -0.226251  -0.095937  ...  0.267649  0.041897 -1.189736   \n",
              "1    -0.502335 -0.039957  -0.066442  ...  0.071330  0.035158 -1.030648   \n",
              "2    -1.141914 -0.813014   0.050106  ... -0.391015 -0.012422 -0.280375   \n",
              "3     0.846662  0.077327  -0.127078  ...  1.274380  0.022824 -0.461370   \n",
              "4    -1.274863  0.094546   0.086084  ... -1.246846 -0.144451 -0.648274   \n",
              "...        ...       ...        ...  ...       ...       ...       ...   \n",
              "9995  0.398832 -0.697020  -0.908464  ... -0.824082  1.953348 -1.289155   \n",
              "9996 -0.801475  1.207871   1.750326  ...  0.001641  0.299031 -0.298962   \n",
              "9997 -1.326083  0.571096   1.479214  ... -0.872030  0.153192  1.061029   \n",
              "9998 -0.685112 -0.607627   0.847203  ...  0.238305  0.074181 -0.727311   \n",
              "9999 -0.863596 -2.069036   0.583513  ...  0.278510  0.074488  1.148716   \n",
              "\n",
              "        XMV(5)    XMV(6)    XMV(7)    XMV(8)    XMV(9)   XMV(10)   XMV(11)  \n",
              "0     0.668457  0.107544 -1.274094  0.412903 -0.127125  0.237093  1.016695  \n",
              "1    -0.311786  0.078098 -0.839560  0.107799 -0.106742  0.306190 -2.047356  \n",
              "2     0.378124 -0.039238  0.727438 -0.578064 -0.164865 -0.857804  0.084772  \n",
              "3     0.130618  0.137652 -0.146024 -2.637652 -0.152536  1.242539  1.330019  \n",
              "4     0.427751 -0.200074  0.937373 -0.258566 -0.163412  1.253446 -1.508929  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "9995 -0.308621 -0.967544  1.667046  1.031606 -0.012472 -0.785365  0.026038  \n",
              "9996 -0.937297  1.636365  0.748596  2.348326  0.078122  0.706400 -0.267121  \n",
              "9997 -1.045897  1.907026 -0.183192  0.186479  0.062480  0.270160 -2.055898  \n",
              "9998 -0.608044  1.061606 -0.567163 -2.718784  0.087738 -0.720289 -0.683127  \n",
              "9999 -1.350102  1.324857 -0.165686  0.863824  0.109756 -1.998293 -0.884715  \n",
              "\n",
              "[10000 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b3a9db4-ba2a-49f0-ba24-8c95a5fde018\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>XMEAS(1)</th>\n",
              "      <th>XMEAS(2)</th>\n",
              "      <th>XMEAS(3)</th>\n",
              "      <th>XMEAS(4)</th>\n",
              "      <th>XMEAS(5)</th>\n",
              "      <th>XMEAS(6)</th>\n",
              "      <th>XMEAS(7)</th>\n",
              "      <th>XMEAS(8)</th>\n",
              "      <th>XMEAS(9)</th>\n",
              "      <th>XMEAS(10)</th>\n",
              "      <th>...</th>\n",
              "      <th>XMV(2)</th>\n",
              "      <th>XMV(3)</th>\n",
              "      <th>XMV(4)</th>\n",
              "      <th>XMV(5)</th>\n",
              "      <th>XMV(6)</th>\n",
              "      <th>XMV(7)</th>\n",
              "      <th>XMV(8)</th>\n",
              "      <th>XMV(9)</th>\n",
              "      <th>XMV(10)</th>\n",
              "      <th>XMV(11)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.048347</td>\n",
              "      <td>0.123632</td>\n",
              "      <td>-0.159818</td>\n",
              "      <td>1.180660</td>\n",
              "      <td>2.005828</td>\n",
              "      <td>0.539664</td>\n",
              "      <td>0.214687</td>\n",
              "      <td>-0.653729</td>\n",
              "      <td>-0.226251</td>\n",
              "      <td>-0.095937</td>\n",
              "      <td>...</td>\n",
              "      <td>0.267649</td>\n",
              "      <td>0.041897</td>\n",
              "      <td>-1.189736</td>\n",
              "      <td>0.668457</td>\n",
              "      <td>0.107544</td>\n",
              "      <td>-1.274094</td>\n",
              "      <td>0.412903</td>\n",
              "      <td>-0.127125</td>\n",
              "      <td>0.237093</td>\n",
              "      <td>1.016695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.041608</td>\n",
              "      <td>0.783922</td>\n",
              "      <td>0.038085</td>\n",
              "      <td>0.923513</td>\n",
              "      <td>-0.340695</td>\n",
              "      <td>2.065275</td>\n",
              "      <td>-0.007759</td>\n",
              "      <td>-0.502335</td>\n",
              "      <td>-0.039957</td>\n",
              "      <td>-0.066442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071330</td>\n",
              "      <td>0.035158</td>\n",
              "      <td>-1.030648</td>\n",
              "      <td>-0.311786</td>\n",
              "      <td>0.078098</td>\n",
              "      <td>-0.839560</td>\n",
              "      <td>0.107799</td>\n",
              "      <td>-0.106742</td>\n",
              "      <td>0.306190</td>\n",
              "      <td>-2.047356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008368</td>\n",
              "      <td>0.090755</td>\n",
              "      <td>0.502525</td>\n",
              "      <td>0.057563</td>\n",
              "      <td>0.528490</td>\n",
              "      <td>0.121041</td>\n",
              "      <td>-0.096771</td>\n",
              "      <td>-1.141914</td>\n",
              "      <td>-0.813014</td>\n",
              "      <td>0.050106</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.391015</td>\n",
              "      <td>-0.012422</td>\n",
              "      <td>-0.280375</td>\n",
              "      <td>0.378124</td>\n",
              "      <td>-0.039238</td>\n",
              "      <td>0.727438</td>\n",
              "      <td>-0.578064</td>\n",
              "      <td>-0.164865</td>\n",
              "      <td>-0.857804</td>\n",
              "      <td>0.084772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.026874</td>\n",
              "      <td>0.120640</td>\n",
              "      <td>-1.176303</td>\n",
              "      <td>1.435335</td>\n",
              "      <td>-1.174407</td>\n",
              "      <td>1.486478</td>\n",
              "      <td>-0.044917</td>\n",
              "      <td>0.846662</td>\n",
              "      <td>0.077327</td>\n",
              "      <td>-0.127078</td>\n",
              "      <td>...</td>\n",
              "      <td>1.274380</td>\n",
              "      <td>0.022824</td>\n",
              "      <td>-0.461370</td>\n",
              "      <td>0.130618</td>\n",
              "      <td>0.137652</td>\n",
              "      <td>-0.146024</td>\n",
              "      <td>-2.637652</td>\n",
              "      <td>-0.152536</td>\n",
              "      <td>1.242539</td>\n",
              "      <td>1.330019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.284680</td>\n",
              "      <td>-0.390610</td>\n",
              "      <td>0.205190</td>\n",
              "      <td>1.077877</td>\n",
              "      <td>-0.043286</td>\n",
              "      <td>-0.173478</td>\n",
              "      <td>0.028830</td>\n",
              "      <td>-1.274863</td>\n",
              "      <td>0.094546</td>\n",
              "      <td>0.086084</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.246846</td>\n",
              "      <td>-0.144451</td>\n",
              "      <td>-0.648274</td>\n",
              "      <td>0.427751</td>\n",
              "      <td>-0.200074</td>\n",
              "      <td>0.937373</td>\n",
              "      <td>-0.258566</td>\n",
              "      <td>-0.163412</td>\n",
              "      <td>1.253446</td>\n",
              "      <td>-1.508929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1.994365</td>\n",
              "      <td>-0.242611</td>\n",
              "      <td>-0.512596</td>\n",
              "      <td>0.758539</td>\n",
              "      <td>-0.528398</td>\n",
              "      <td>-0.228012</td>\n",
              "      <td>-1.615394</td>\n",
              "      <td>0.398832</td>\n",
              "      <td>-0.697020</td>\n",
              "      <td>-0.908464</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.824082</td>\n",
              "      <td>1.953348</td>\n",
              "      <td>-1.289155</td>\n",
              "      <td>-0.308621</td>\n",
              "      <td>-0.967544</td>\n",
              "      <td>1.667046</td>\n",
              "      <td>1.031606</td>\n",
              "      <td>-0.012472</td>\n",
              "      <td>-0.785365</td>\n",
              "      <td>0.026038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.110475</td>\n",
              "      <td>2.236481</td>\n",
              "      <td>-0.337915</td>\n",
              "      <td>-1.134547</td>\n",
              "      <td>-1.372783</td>\n",
              "      <td>-0.288344</td>\n",
              "      <td>-1.600317</td>\n",
              "      <td>-0.801475</td>\n",
              "      <td>1.207871</td>\n",
              "      <td>1.750326</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001641</td>\n",
              "      <td>0.299031</td>\n",
              "      <td>-0.298962</td>\n",
              "      <td>-0.937297</td>\n",
              "      <td>1.636365</td>\n",
              "      <td>0.748596</td>\n",
              "      <td>2.348326</td>\n",
              "      <td>0.078122</td>\n",
              "      <td>0.706400</td>\n",
              "      <td>-0.267121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.256299</td>\n",
              "      <td>-0.693700</td>\n",
              "      <td>0.542803</td>\n",
              "      <td>-0.634375</td>\n",
              "      <td>-0.124653</td>\n",
              "      <td>2.101598</td>\n",
              "      <td>-1.810683</td>\n",
              "      <td>-1.326083</td>\n",
              "      <td>0.571096</td>\n",
              "      <td>1.479214</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.872030</td>\n",
              "      <td>0.153192</td>\n",
              "      <td>1.061029</td>\n",
              "      <td>-1.045897</td>\n",
              "      <td>1.907026</td>\n",
              "      <td>-0.183192</td>\n",
              "      <td>0.186479</td>\n",
              "      <td>0.062480</td>\n",
              "      <td>0.270160</td>\n",
              "      <td>-2.055898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.045981</td>\n",
              "      <td>0.011734</td>\n",
              "      <td>-0.586771</td>\n",
              "      <td>-1.741825</td>\n",
              "      <td>-0.515844</td>\n",
              "      <td>-1.184408</td>\n",
              "      <td>-1.855771</td>\n",
              "      <td>-0.685112</td>\n",
              "      <td>-0.607627</td>\n",
              "      <td>0.847203</td>\n",
              "      <td>...</td>\n",
              "      <td>0.238305</td>\n",
              "      <td>0.074181</td>\n",
              "      <td>-0.727311</td>\n",
              "      <td>-0.608044</td>\n",
              "      <td>1.061606</td>\n",
              "      <td>-0.567163</td>\n",
              "      <td>-2.718784</td>\n",
              "      <td>0.087738</td>\n",
              "      <td>-0.720289</td>\n",
              "      <td>-0.683127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.045674</td>\n",
              "      <td>-1.186775</td>\n",
              "      <td>-0.627300</td>\n",
              "      <td>-0.362506</td>\n",
              "      <td>0.993095</td>\n",
              "      <td>-0.685113</td>\n",
              "      <td>-2.353346</td>\n",
              "      <td>-0.863596</td>\n",
              "      <td>-2.069036</td>\n",
              "      <td>0.583513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278510</td>\n",
              "      <td>0.074488</td>\n",
              "      <td>1.148716</td>\n",
              "      <td>-1.350102</td>\n",
              "      <td>1.324857</td>\n",
              "      <td>-0.165686</td>\n",
              "      <td>0.863824</td>\n",
              "      <td>0.109756</td>\n",
              "      <td>-1.998293</td>\n",
              "      <td>-0.884715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b3a9db4-ba2a-49f0-ba24-8c95a5fde018')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b3a9db4-ba2a-49f0-ba24-8c95a5fde018 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b3a9db4-ba2a-49f0-ba24-8c95a5fde018');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dtale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pjF2cC8KcqgN",
        "outputId": "1eea06af-027e-4dc8-bc75-d7e1e938e540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dtale\n",
            "  Downloading dtale-2.12.3-py2.py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Flask-Compress\n",
            "  Downloading Flask_Compress-1.13-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from dtale) (0.11.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from dtale) (2022.12.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from dtale) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from dtale) (1.0.2)\n",
            "Collecting scipy==1.9.3\n",
            "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from dtale) (1.3.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from dtale) (5.5.0)\n",
            "Collecting strsimpy\n",
            "  Downloading strsimpy-0.2.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dash-colorscales\n",
            "  Downloading dash_colorscales-0.0.4.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.6.0\n",
            "  Downloading matplotlib-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous in /usr/local/lib/python3.8/dist-packages (from dtale) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from dtale) (2.25.1)\n",
            "Requirement already satisfied: future>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from dtale) (0.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from dtale) (4.6.3)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.8/dist-packages (from dtale) (1.1.4)\n",
            "Collecting dash-daq\n",
            "  Downloading dash_daq-0.5.0.tar.gz (642 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m642.7/642.7 KB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.8/dist-packages (from dtale) (1.2.0)\n",
            "Collecting dash-bootstrap-components<=1.3.1\n",
            "  Downloading dash_bootstrap_components-1.3.1-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.7/219.7 KB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler in /usr/local/lib/python3.8/dist-packages (from dtale) (0.11.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from dtale) (0.12.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from dtale) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dtale) (1.22.4)\n",
            "Collecting dash>=2.0.0\n",
            "  Downloading dash-2.8.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from dtale) (3.0)\n",
            "Collecting lz4\n",
            "  Downloading lz4-4.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.8/dist-packages (from dtale) (3.0.10)\n",
            "Collecting squarify\n",
            "  Downloading squarify-0.4.3-py3-none-any.whl (4.3 kB)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.8/dist-packages (from dtale) (2022.12.0)\n",
            "Collecting missingno<=0.4.2\n",
            "  Downloading missingno-0.4.2-py3-none-any.whl (9.7 kB)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0->dtale) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0->dtale) (4.38.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0->dtale) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0->dtale) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0->dtale) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0->dtale) (1.4.4)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dash-html-components==2.0.0\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask->dtale) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask->dtale) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask->dtale) (7.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dtale) (8.2.1)\n",
            "Collecting brotli\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->dtale) (2022.7.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->dtale) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->dtale) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->dtale) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->dtale) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->dtale) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->dtale) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->dtale) (2.0.1)\n",
            "Building wheels for collected packages: dash-colorscales, dash-daq\n",
            "  Building wheel for dash-colorscales (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-colorscales: filename=dash_colorscales-0.0.4-py3-none-any.whl size=62589 sha256=703e706e962a6fcd10039039d485e8c11f4a4e2b22b23f9ba649a475f01268b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/33/33/172dbfe1efc739352828854a113df599a428b58f68ed0c4f75\n",
            "  Building wheel for dash-daq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-daq: filename=dash_daq-0.5.0-py3-none-any.whl size=669715 sha256=f3c0c60bbb154eea04dbd76c0aa3827f7f13b5e644dbc6bb17f867e15d094638\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/35/e5/57e90f10c529601c6627400513cb65dd5adb09752411f5a050\n",
            "Successfully built dash-colorscales dash-daq\n",
            "Installing collected packages: strsimpy, squarify, kaleido, dash-table, dash-html-components, dash-core-components, dash-colorscales, brotli, scipy, lz4, contourpy, matplotlib, flask-ngrok, Flask-Compress, dash, missingno, dash-daq, dash-bootstrap-components, dtale\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.5.3\n",
            "    Uninstalling matplotlib-3.5.3:\n",
            "      Successfully uninstalled matplotlib-3.5.3\n",
            "  Attempting uninstall: missingno\n",
            "    Found existing installation: missingno 0.5.1\n",
            "    Uninstalling missingno-0.5.1:\n",
            "      Successfully uninstalled missingno-0.5.1\n",
            "Successfully installed Flask-Compress-1.13 brotli-1.0.9 contourpy-1.0.7 dash-2.8.1 dash-bootstrap-components-1.3.1 dash-colorscales-0.0.4 dash-core-components-2.0.0 dash-daq-0.5.0 dash-html-components-2.0.0 dash-table-5.0.0 dtale-2.12.3 flask-ngrok-0.0.25 kaleido-0.2.1 lz4-4.3.2 matplotlib-3.6.0 missingno-0.4.2 scipy-1.9.3 squarify-0.4.3 strsimpy-0.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dtale\n",
        "import pandas as pd\n",
        "\n",
        "d = dtale.show(X_train)\n",
        "d.open_browser()"
      ],
      "metadata": {
        "id": "5Q9bz1P0d4Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "pip install pyod combo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTBS98fIhlVF",
        "outputId": "2db777ca-d405-47d6-d15b-8e118b639127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyod\n",
            "  Downloading pyod-1.0.7.tar.gz (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.7/147.7 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting combo\n",
            "  Downloading combo-0.1.3.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pyod) (1.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from pyod) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.8/dist-packages (from pyod) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from pyod) (1.7.3)\n",
            "Requirement already satisfied: scikit_learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from pyod) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pyod) (0.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.51->pyod) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.51->pyod) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.51->pyod) (0.39.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn>=0.20.0->pyod) (3.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pyod) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pyod) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pyod) (3.0.9)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pyod) (0.5.3)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pyod) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21->statsmodels->pyod) (2022.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.51->pyod) (3.12.1)\n",
            "Building wheels for collected packages: pyod, combo\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.0.7-py3-none-any.whl size=181101 sha256=03dc822d55168672faca0377c117de0a762d53422e673247972de50cd14f154d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/e2/c1/1c7fd8b261e72411f6509afb429c84532e40ddcd96074473f4\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.3-py3-none-any.whl size=42885 sha256=c9760cfd3b3fcf2d7577dde46d1974e5fbaec75aa6f7201a7b310d05513774dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/44/39/0667fea44a2dfe692cc2a51f0f79ea49b9dee7def53594ef2e\n",
            "Successfully built pyod combo\n",
            "Installing collected packages: pyod, combo\n",
            "Successfully installed combo-0.1.3 pyod-1.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "from torch.nn import Module\n",
        "from torch.nn import functional as F\n",
        "from torch import nn\n",
        "from pyod.models.auto_encoder_torch import AutoEncoder\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "-f7Sy4hLjALi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder Loss Function Simple Comparison"
      ],
      "metadata": {
        "id": "TxBCMFf0k8M-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Explanation \n",
        "\n",
        "### **Cosine Loss**\n",
        "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. In the context of a loss function for an autoencoder, we want to minimize the difference between the reconstructed data and the original input data.\n",
        "\n",
        "The cosine similarity loss function can be defined mathematically as:\n",
        "\n",
        "cosine_similarity$(x_1, x_2) = \\frac{x_1 \\cdot x_2}{\\left\\lVert x_1\\right\\rVert \\left\\lVert x_2 \\right\\rVert} = \\frac{\\sum_{i=1}^{n} x_{1,i} x_{2,i}}{\\sqrt{\\sum_{i=1}^{n} x_{1,i}^2}\\sqrt{\\sum_{i=1}^{n} x_{2,i}^2}}$\n",
        "\n",
        "where $x_1$ and $x_2$ are vectors, $n$ is the number of elements in the vectors, and $x_{1,i}$ and $x_{2,i}$ are the $i^{th}$ elements of the vectors.\n",
        "\n",
        "The cosine similarity loss is then defined as 1 - cosine_similarity$(x_1, x_2)$. In other words, we subtract the cosine similarity value from 1 to get the loss. The goal is to minimize this loss, meaning that the similarity between the reconstructed data and the original input data is maximized.\n",
        "\n",
        "### **Principal Angle**\n",
        "The Principal Angle Loss implementation that was provided can be described as follows. The objective is to calculate the principal angle between the reconstructed data, $\\mathbf{R}$, and the original data, $\\mathbf{X}$. This is done by computing the dot product between the normalized versions of $\\mathbf{R}$ and $\\mathbf{X}$, and then using the result to compute the cosine of the principal angle between the two vectors. The loss value is defined as the mean of these principal angles.\n",
        "\n",
        "Given two matrices, $\\mathbf{R} \\in \\mathbb{R}^{m \\times n}$ and $\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$, where $m$ is the number of data points and $n$ is the dimension of each data point, the implementation first normalizes the matrices by dividing each data point by its norm. The normalized matrices are represented by $\\hat{\\mathbf{R}}$ and $\\hat{\\mathbf{X}}$ respectively.\n",
        "\n",
        "The dot product between $\\hat{\\mathbf{R}}$ and $\\hat{\\mathbf{X}}^T$ is computed, resulting in a matrix, $\\mathbf{D} \\in \\mathbb{R}^{n \\times n}$, where $\\mathbf{D}_{i,j}$ is the dot product between the $i^{th}$ row of $\\hat{\\mathbf{R}}$ and the $j^{th}$ row of $\\hat{\\mathbf{X}}^T$. The diagonal of $\\mathbf{D}$ contains the dot products between the corresponding rows of $\\hat{\\mathbf{R}}$ and $\\hat{\\mathbf{X}}$, which represent the cosine of the angles between the corresponding data points in $\\mathbf{R}$ and $\\mathbf{X}$.\n",
        "\n",
        "The cosine of the principal angle between two vectors, $\\mathbf{a}$ and $\\mathbf{b}$, can be represented by the dot product of the normalized vectors, $\\hat{\\mathbf{a}}$ and $\\hat{\\mathbf{b}}$, i.e., $\\cos \\theta = \\hat{\\mathbf{a}} \\cdot \\hat{\\mathbf{b}}$. Hence, the cosine of the principal angle between the $i^{th}$ data point in $\\mathbf{R}$ and the corresponding data point in $\\mathbf{X}$ can be represented by $\\mathbf{D}_{i,i}$.\n",
        "\n",
        "The principal angle between two vectors is the angle between them in a high-dimensional space. It can be computed using the inverse cosine function, i.e., $\\theta = \\arccos (\\cos \\theta)$. Hence, the principal angle between the $i^{th}$ data point in $\\mathbf{R}$ and the corresponding data point in $\\mathbf{X}$ can be represented by $\\arccos(\\mathbf{D}_{i,i})$.\n",
        "\n",
        "The final loss value is defined as the mean of all the principal angles, i.e.,\n",
        "\n",
        "$$L = \\frac{1}{n} \\sum_{i=1}^{n} \\arccos(\\mathbf{D}_{i,i})$$\n",
        "\n",
        "### **One Class SVM**\n",
        "\n",
        "The One-Class SVM Loss is a loss function used in unsupervised anomaly detection, where the goal is to detect patterns that are significantly different from the majority of the data. The loss function is designed to encourage the autoencoder to learn a representation that is similar to the majority of the data in terms of reconstruction error.\n",
        "\n",
        "The loss function is defined as follows:\n",
        "\n",
        "Let $x$ be the original input to the autoencoder and $\\hat{x}$ be its reconstructed output. Let $n$ be the number of samples. Then, the mean reconstruction error for each sample is calculated as follows:\n",
        "\n",
        "$$\\mathrm{scores}_i = \\frac{1}{d} \\sum{j=1}^{d} (\\hat{x}_{i,j} - x_{i,j})^2$$\n",
        "\n",
        "where $d$ is the number of features for each sample.\n",
        "\n",
        "The negative samples are defined as the mean reconstruction errors that are greater than or equal to 1:\n",
        "\n",
        "$$\\mathrm{negative}_{samples_i} = \\begin{cases} \\mathrm{scores}_i & \\text{if } \\mathrm{scores}_i \\geq 1 \\ 0 & \\text{otherwise} \\end{cases}$$\n",
        "\n",
        "The negative loss is calculated as the sum of the negative samples, which is clamped to 0 for any negative values:\n",
        "\n",
        "$$\\mathrm{negative_{loss}} = \\sum_{i=1}^{n} \\max(\\mathrm{negative}, 0)$$\n",
        "\n",
        "Finally, the One-Class SVM Loss is calculated as the weighted average of the negative loss, where the weight is determined by the regularization parameter $\\nu$:\n",
        "\n",
        "$$\\mathrm{loss} = \\frac{\\nu}{n} \\mathrm{negative}_{loss}$$\n"
      ],
      "metadata": {
        "id": "UtQptbgPVxfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Loss Functions"
      ],
      "metadata": {
        "id": "3ivOx8TxlCBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " class CosineLoss(nn.Module):\n",
        "    \"\"\"Cosine Loss module to compute the cosine similarity between two input tensors.\n",
        "    \n",
        "    Args:\n",
        "        dim (int, optional): The dimension along which the cosine similarity will be computed. Default is 1.\n",
        "        eps (float, optional): Small value added to the denominator to prevent division by zero. Default is 1e-8.\n",
        "        \n",
        "    Returns:\n",
        "        Tensor: The computed cosine loss.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int = 1, eps: float = 1e-8) -> None:\n",
        "        super(CosineLoss, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Computes the cosine similarity between two input tensors.\n",
        "        \n",
        "        Args:\n",
        "            x1 (torch.Tensor): First input tensor.\n",
        "            x2 (torch.Tensor): Second input tensor.\n",
        "            \n",
        "        Returns:\n",
        "            Tensor: The cosine similarity loss between the two input tensors.\n",
        "        \"\"\"\n",
        "        similarity = F.cosine_similarity(x1, x2, dim=self.dim, eps=self.eps)\n",
        "        loss = 1 - torch.mean(similarity)\n",
        "        return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "K68AGBlbSVaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OneClassSVMLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of the One-Class SVM Loss for unsupervised anomaly detection.\n",
        "    The loss is calculated based on the reconstruction error between the input and its reconstructed output.\n",
        "\n",
        "    This implementation calculates the One-Class SVM Loss based on the mean reconstruction error between \n",
        "    the input and its reconstructed output. The loss is then regularized by a parameter nu that determines \n",
        "    the trade-off between the maximum mean reconstruction error and the number of violations. \n",
        "    The mean reconstruction error is calculated by taking the mean of the squared differences between \n",
        "    recon_x and x along each sample. The negative samples are then clamped to 0 if they are less than 1, \n",
        "    and the final loss is calculated by taking the sum of the negative samples and multiplying it by nu \n",
        "    divided by the number of samples.\n",
        "    \"\"\"\n",
        "    def __init__(self, nu=0.1):\n",
        "        \"\"\"\n",
        "        Initialization of the One-Class SVM Loss class.\n",
        "        :param nu: The regularization parameter that determines the trade-off between the maximum mean reconstruction error and the number of violations.\n",
        "        \"\"\"\n",
        "        super(OneClassSVMLoss, self).__init__()\n",
        "        self.nu = nu\n",
        "    \n",
        "    def forward(self, recon_x, x):\n",
        "        \"\"\"\n",
        "        Calculates the One-Class SVM Loss.\n",
        "        :param recon_x: The reconstructed output of the autoencoder.\n",
        "        :param x: The original input to the autoencoder.\n",
        "        :return: The calculated loss.\n",
        "        \"\"\"\n",
        "        scores = torch.mean((recon_x - x)**2, dim=1) # Calculate the mean reconstruction error along each sample\n",
        "        negative_samples = scores\n",
        "        negative_loss = torch.clamp(negative_samples + 1, min=0).sum() # Clamp all scores that are less than 1 to 0\n",
        "        loss = self.nu * negative_loss / scores.size(0) # Calculate the final loss\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W8KKCXAtlAAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrincipalAngleLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    A custom PyTorch loss function that calculates the principal angle between\n",
        "    the reconstructed data and the original data in an autoencoder. The loss\n",
        "    function encourages the autoencoder to learn a representation that is\n",
        "    similar to the original data in terms of the principal angles between the\n",
        "    data points.\n",
        "\n",
        "    The computation of the principal angle is more computationally efficient than using a Hankel matrix, \n",
        "    singular value decomposition (SVD), and then the principal angle for several reasons:\n",
        "    1. Avoiding the Hankel Matrix Construction: The Hankel matrix construction involves creating a \n",
        "    matrix from the data by concatenating its shifted versions. This can be computationally expensive \n",
        "    for large datasets.\n",
        "\n",
        "    2. Avoiding the SVD: The singular value decomposition (SVD) of a matrix involves finding its \n",
        "    eigenvalues and eigenvectors. This can be computationally expensive, especially for large matrices.\n",
        "    \n",
        "    3. Using dot products instead of eigenvalues and eigenvectors: In this class, the cosine of the \n",
        "    principal angle is computed using the dot product of the normalized vectors, which is more \n",
        "    computationally efficient than computing the angle using eigenvalues and eigenvectors.\n",
        "    \n",
        "    4. Using vector operations instead of matrix operations: This class performs operations on \n",
        "    individual vectors instead of matrices, which is more computationally efficient.\n",
        "    \n",
        "    \n",
        "    Parameters:\n",
        "    None\n",
        "\n",
        "    Attributes:\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the PrincipalAngleLoss class by calling the super class\n",
        "        constructor.\n",
        "        \"\"\"\n",
        "        super(PrincipalAngleLoss, self).__init__()\n",
        "\n",
        "    def forward(self, recon_x, x):\n",
        "        \"\"\"\n",
        "        Computes the principal angle loss between the reconstructed data and the\n",
        "        original data. The input data (recon_x and x) are first normalized by\n",
        "        dividing by their norms. The dot product of the two normalized vectors\n",
        "        is calculated and then used to compute the cosine of the principal angle\n",
        "        between the two vectors. The principal angle is then calculated using\n",
        "        the acos function, and the mean of the angles is used as the loss value.\n",
        "\n",
        "        Parameters:\n",
        "        recon_x (Tensor): The reconstructed data.\n",
        "        x (Tensor): The original data.\n",
        "\n",
        "        Returns:\n",
        "        loss (Tensor): The principal angle loss between the reconstructed data\n",
        "            and the original data.\n",
        "        \"\"\"\n",
        "        recon_x = recon_x / recon_x.norm(dim=1, keepdim=True)\n",
        "        x = x / x.norm(dim=1, keepdim=True)\n",
        "        recon_x_t = recon_x.t()\n",
        "        dot_prod = torch.mm(recon_x, x.t())\n",
        "        cos_theta = dot_prod.diagonal(dim1=-2, dim2=-1)\n",
        "        theta = torch.acos(cos_theta)\n",
        "        loss = theta.mean()\n",
        "        return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "A01eAgCROaaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_ae = AutoEncoder(loss_fn = CosineLoss(),epochs = 100,hidden_neurons = [52,26,13],batch_size = 64,preprocessing  = False)\n",
        "mse_ae = AutoEncoder(epochs = 100,hidden_neurons = [52,26,13],batch_size = 64,preprocessing  = False)\n",
        "pa_ae = AutoEncoder(loss_fn = PrincipalAngleLoss(),epochs = 100,hidden_neurons = [52,26,13],batch_size = 64,preprocessing  = False)\n",
        "ocsvm_ae = AutoEncoder(loss_fn = OneClassSVMLoss(),epochs = 100,hidden_neurons = [52,26,13],batch_size = 64,preprocessing  = False)\n"
      ],
      "metadata": {
        "id": "9Jlf_YUolPMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train AE's"
      ],
      "metadata": {
        "id": "SFdBrUAqlhO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)        \n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "xx,yy = create_sequences(X_train, y_train, time_steps=10)"
      ],
      "metadata": {
        "id": "CFtTgI6eSsax",
        "outputId": "1466d640-5b70-4b07-cfe8-cd991bb33f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-db1234c58176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_ae.fit(xx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "rynT3WCLTRUQ",
        "outputId": "673602b4-db88-460a-a05a-ba177241daa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e9212017947b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmse_ae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyod/models/auto_encoder_torch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# validate inputs X and y (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    792\u001b[0m                 ) from e\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_ae.fit(X_train)\n",
        "mse_ae.fit(X_train)\n",
        "pa_ae.fit(X_train)\n",
        "ocsvm_ae.fit(X_train)"
      ],
      "metadata": {
        "id": "GTqRsk8blfrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "ubONnyYQlqY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_cosine = cosine_ae.predict(X_test)\n",
        "pred_mse = mse_ae.predict(X_test)\n",
        "pred_pa = pa_ae.predict(X_test)\n",
        "pred_ocsvm = ocsvm_ae.predict(X_test)"
      ],
      "metadata": {
        "id": "n4YTUgMkloe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results ROC-AUC"
      ],
      "metadata": {
        "id": "xsxdVf9rl4Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auc_cosine = roc_auc_score(y_test,pred_cosine)\n",
        "auc_mse = roc_auc_score(y_test,pred_mse)\n",
        "auc_pa = roc_auc_score(y_test,pred_pa)\n",
        "auc_ocsvm = roc_auc_score(y_test,pred_ocsvm)\n",
        "print('ROC-AUC Cosine: ' + str(auc_cosine))\n",
        "print('ROC-AUC MSE: ' + str(auc_mse))\n",
        "print('ROC-AUC PA: ' + str(auc_pa))\n",
        "print('ROC-AUC OCSVM: ' + str(auc_ocsvm ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqn4NHVFl5f5",
        "outputId": "f7ccd8fd-1a6a-4615-a743-cdeccd8faefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Cosine: 0.8836756748937652\n",
            "ROC-AUC MSE: 0.9039868244183978\n",
            "ROC-AUC PA: 0.8587966535406711\n",
            "ROC-AUC OCSVM: 0.9057719747861256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZbi4OEaTjaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import trange\n",
        "import tqdm\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "a6dNth8RfZG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "G7mOuwvFNT7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "        \n",
        "data = X_train.values\n",
        "sequence_length = 10\n",
        "batch_size = 30\n",
        "sequences = [data[i:i + sequence_length] for i in range(data.shape[0] - sequence_length + 1)]\n",
        "data_loader = DataLoader(dataset=sequences, batch_size=batch_size, shuffle=False, drop_last=False)\n"
      ],
      "metadata": {
        "id": "PyFhC515OzQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.linalg import hankel, svd, subspace_angles\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JbUSRMe1m_Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.linalg import hankel, subspace_angles\n",
        "\n",
        "class PALossTS(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PALossTS, self).__init__()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # Compute the Hankel matrices for x and y\n",
        "        hx = torch.tensor(hankel(x.unsqueeze(1).detach().numpy()))\n",
        "        hy = torch.tensor(hankel(y.unsqueeze(1).detach().numpy()))\n",
        "\n",
        "        # Compute the truncated SVD for the Hankel matrices\n",
        "        _, sx, _ = torch.svd_lowrank(hx)\n",
        "        _, sy, _ = torch.svd_lowrank(hy)\n",
        "\n",
        "        # Compute the principal angles between the SVD subspaces\n",
        "        cos_angles = torch.tensor(subspace_angles(sx.detach().numpy(), sy.detach().numpy()))\n",
        "\n",
        "        # Calculate the loss as the sum of the cosine of the principal angles\n",
        "        loss = torch.sum(torch.cos(cos_angles))\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "bGyjHZswu76r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class TimeSeriesAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim):\n",
        "        super(TimeSeriesAutoencoder, self).__init__()\n",
        "        \n",
        "        # Define the encoder network\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, encoding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        # Define the decoder network\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "    \n",
        "# Define the hyperparameters\n",
        "input_dim = 52 # Dimension of each time step in the input data\n",
        "encoding_dim = 10 # Dimension of the compressed representation\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "\n",
        "# Initialize the autoencoder model and optimizer\n",
        "model = TimeSeriesAutoencoder(input_dim, encoding_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.MSELoss()\n",
        "criterion = PALossTS()\n",
        "criterion = OneClassSVMLoss()\n",
        "'''\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for ts in data_loader:\n",
        "      # Generate a random input sequence for each batch\n",
        "      #x = torch.rand(32, input_dim)\n",
        "      \n",
        "      # Forward pass and calculate loss\n",
        "      output = model(ts.float())\n",
        "      loss = criterion(output, ts.float())\n",
        "      print(loss)\n",
        "      # Backward pass and update parameters\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Print the loss for every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "'''\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # Generate a random input sequence for each batch\n",
        "    x = torch.rand(32, input_dim)\n",
        "    \n",
        "    # Forward pass and calculate loss\n",
        "    output = model(x)\n",
        "    loss = criterion(output, x)\n",
        "    \n",
        "    # Backward pass and update parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Print the loss for every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX34uoY3m1D5",
        "outputId": "23216371-6337-4c83-f8d8-b0ba57fc4a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.1084\n",
            "Epoch [11/100], Loss: 0.1086\n",
            "Epoch [21/100], Loss: 0.1086\n",
            "Epoch [31/100], Loss: 0.1084\n",
            "Epoch [41/100], Loss: 0.1081\n",
            "Epoch [51/100], Loss: 0.1084\n",
            "Epoch [61/100], Loss: 0.1083\n",
            "Epoch [71/100], Loss: 0.1082\n",
            "Epoch [81/100], Loss: 0.1080\n",
            "Epoch [91/100], Loss: 0.1080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy.linalg import hankel, svd, subspace_angles\n",
        "\n",
        "def custom_loss(x, y):\n",
        "    # Calculate the Hankel matrix for x and y\n",
        "    hx = torch.tensor(hankel(x))\n",
        "    hy = torch.tensor(hankel(y))\n",
        "    \n",
        "    # Compute the SVD for the Hankel matrices\n",
        "    _, sx, _ = torch.svd(hx)\n",
        "    _, sy, _ = torch.svd(hy)\n",
        "    \n",
        "    # Compute the principal angles between the SVD subspaces\n",
        "    cos_angles = torch.tensor(subspace_angles(sx.numpy(), sy.numpy()))\n",
        "    \n",
        "    # Calculate the loss as the sum of the cosine of the principal angles\n",
        "    loss = torch.sum(torch.cos(cos_angles))\n",
        "    \n",
        "    return loss"
      ],
      "metadata": {
        "id": "a8KTAy35m1VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BYkUChQqO3v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}